# -*- coding: utf-8 -*-
"""project1_pretictive_analytic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mZIxe-ipg3mwj3YatmXlLJlT2_VerrgP

# Proyek Klasifikasi Kanker Payudara

## Pendahuluan
Proyek ini bertujuan untuk membangun model machine learning yang dapat mengklasifikasikan tumor payudara sebagai **malignant** (kanker) atau **benign** (non-kanker) berdasarkan fitur-fitur yang diukur dari dataset Breast Cancer Wisconsin. Dataset ini berisi pengukuran karakteristik tumor seperti radius, tekstur, dan lainnya.

**Tujuan:**
- Membangun model klasifikasi dengan akurasi tinggi.
- Membandingkan performa beberapa algoritma (Logistic Regression, Random Forest, SVM) dengan metode seleksi fitur (SelectKBest, RFE).
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
# keeps the plots in one place. calls image as static pngs
# %matplotlib inline
import matplotlib.gridspec as gridspec # subplots
#Import models from scikit learn module:
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import warnings
from sklearn.model_selection import GridSearchCV
warnings.filterwarnings('ignore')
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import RFE

from google.colab import files
files.upload()  # upload kaggle.json kamu

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download kaggle dataset and unzip the file
# !cp kaggle.json ~/.kaggle/

# !chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d uciml/breast-cancer-wisconsin-data
!unzip breast-cancer-wisconsin-data.zip

"""# Data Understanding

## Data Loading
"""

df = pd.read_csv("/content/data.csv")
df

"""**Insight:**

*   Dataset memiliki 569 baris (pengamatan) dan 33 kolom (fitur + target).
*   Kolom diagnosis adalah target dengan nilai M (malignant) dan B (benign).
*   Kolom id tidak relevan untuk modeling, dan kolom Unnamed: 32 berisi nilai kosong.

## Exploratory Data Analysis
"""

df.head()

df.info()

"""**Insight:**
- Tidak ada missing value pada fitur utama, kecuali kolom Unnamed: 32 yang sepenuhnya kosong.
"""

df.describe()

"""**Insight:**
- Kode ini untuk melihat statistik deskriptif dari dataset Breast Cancer

### Menangani Missing Value
"""

df.isnull().sum()

"""**Insight:**
- Unnamed: 32 memiliki 562 nilai kosong dan harus dilakukan tindakan

### Data Preprocessing
"""

df.drop('id',axis=1, inplace=True)
df.drop('Unnamed: 32',axis=1, inplace=True)

"""**Insight:**
- Melakukan tindakan drop untuk kolom yang tidak relevan seperti Id dan data yang kosong (Unnamed: 32)

### Prepare data target
"""

df.diagnosis.unique()

"""**Insight:**
- Data target memiliki 2 nilai yaitu 'M': malignant, 'B': benign
"""

df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})
df.head()

"""**Insight:**
- Mengubah data target menjadi numerik yaitu 1 untuk malignant(M) atau kanker ganas dan 0 Benign(B) atau kanker jinak
"""

# Plot distribusi target
plt.figure(figsize=(6, 4))
sns.countplot(x='diagnosis', data=df, palette='Set2')
plt.title('Distribusi Diagnosis (1: Malignant, 0: Benign)')
plt.xlabel('Diagnosis')
plt.ylabel('Jumlah')
plt.xticks([0, 1], ['Benign', 'Malignant'])
plt.show()

print(df['diagnosis'].value_counts())

"""**Insight:**

- B memiliki data 357 dan M memiliki 212

- Distribusi target menunjukkan lebih banyak kasus benign (63%) dibandingkan malignant (37%), tetapi tidak terlalu imbalanced
"""

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=False, cmap='coolwarm')
plt.title('Korelasi Antar Fitur')
# Simpan gambar ke file PNG
plt.savefig('heatmap_korelasi.png', dpi=300, bbox_inches='tight')
plt.show()

# Korelasi antar fitur (heatmap)
corr = df.corr()

# Menghitung korelasi antara fitur dan target
correlation_with_target = df.corr()['diagnosis'].abs().sort_values(ascending=False)

# Menampilkan korelasi
print(correlation_with_target)

"""**Insight:**

- Fitur seperti concave points_worst, perimeter_worst, dan radius_worst memiliki korelasi tinggi dengan target (diagnosis).
- Beberapa fitur memiliki korelasi rendah (< 0.1), yang mungkin tidak terlalu informatif untuk model.

# Data Preparation
"""

X = df.drop('diagnosis', axis=1)
y = df['diagnosis']

"""**Insight:**
- Memisahkan fitur dan target
"""

# Membagi data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""**Insight:**
- Pembagian data train-test untuk memastikan model dievaluasi pada data yang belum pernah dilihat.
- Data dibagi dengan rasio 80:20 (train:test), dengan stratify untuk menjaga proporsi kelas.
"""

# Standarisasi fitur
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""**Insight:**
- Standarisasi mengubah fitur ke skala yang sama (mean=0, std=1).
- Standarisasi diperlukan karena beberapa algoritma (seperti SVM) sensitif terhadap skala fitur.

# Feature Selection

### SelectKBest
"""

# ----------------------------------------
# Feature Selection dengan SelectKBest
# ----------------------------------------
k = 10  # Jumlah fitur yang diambil
skb = SelectKBest(score_func=f_classif, k=k)
X_train_skb = skb.fit_transform(X_train_scaled, y_train)
X_test_skb = skb.transform(X_test_scaled)

skb_features = X.columns[skb.get_support()]
print("Fitur dari SelectKBest:", skb_features.tolist())

"""**Insight:**
- Menggunakan SelectKBest untuk memilih 10 fitur terbaik berdasarkan skor ANOVA F-value.

- Fitur terpilih mencakup'radius_mean', 'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean', 'radius_worst', 'perimeter_worst', 'area_worst', 'concavity_worst', 'concave points_worst', yang konsisten dengan korelasi tinggi terhadap target.

### RFE

**Insight**
- Menggunakan RFE dengan tiga algoritma: Logistic Regression, Random Forest, dan SVM.

### Logistic Regression
"""

# ----------------------------------------
# Feature Selection dengan RFE
# ----------------------------------------
rfe = RFE(estimator=LogisticRegression(), n_features_to_select=k)
rfe.fit(X_train_scaled, y_train)

X_train_rfe = rfe.transform(X_train_scaled)
X_test_rfe = rfe.transform(X_test_scaled)

rfe_features = X.columns[rfe.support_]
print("Fitur dari RFE LR:", rfe_features.tolist())

"""**Insight:**
- Fitur terpilih mencakup 'concave points_mean', 'radius_se', 'area_se', 'compactness_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'concavity_worst', 'concave points_worst', yang konsisten dengan korelasi tinggi terhadap target.

### Random Forest
"""

# Jumlah fitur yang ingin dipilih
k = 10

# Inisialisasi RFE dengan Random Forest
rfe_rf = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=k)
rfe_rf.fit(X_train_scaled, y_train)

# Transformasi data
X_train_rfe_rf = rfe_rf.transform(X_train_scaled)
X_test_rfe_rf = rfe_rf.transform(X_test_scaled)

# Menampilkan nama fitur
rfe_features_rf = X.columns[rfe_rf.support_]
print("Fitur dari RFE (Random Forest):", rfe_features_rf.tolist())

"""**Insight:**
- Fitur terpilih mencakup 'radius_mean', 'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'concave points_worst', yang konsisten dengan korelasi tinggi terhadap target.

### SVM
"""

# Inisialisasi RFE dengan SVM (gunakan linear kernel agar bisa menghitung ranking)
rfe_svm = RFE(estimator=SVC(kernel="linear", random_state=42), n_features_to_select=k)
rfe_svm.fit(X_train_scaled, y_train)

# Transformasi data
X_train_rfe_svm = rfe_svm.transform(X_train_scaled)
X_test_rfe_svm = rfe_svm.transform(X_test_scaled)

# Menampilkan nama fitur
rfe_features_svm = X.columns[rfe_svm.support_]
print("Fitur dari RFE (SVM):", rfe_features_svm.tolist())

"""**Insight:**
- Fitur terpilih mencakup 'concavity_mean', 'concave points_mean', 'radius_se', 'texture_se', 'area_se', 'compactness_se', 'fractal_dimension_se', 'texture_worst', 'area_worst', 'concavity_worst', yang konsisten dengan korelasi tinggi terhadap target.

**Insight:**
- ### RFE dengan Random Forest memilih fitur yang mirip dengan SelectKBest, menunjukkan konsistensi.


- ### RFE dengan SVM memilih beberapa fitur berbeda, seperti texture_se dan fractal_dimension_se.

# Modelling

### SelectKbest
"""

def evaluate_model(name, y_true, y_pred):
    print(f"\nModel: {name}")
    print("Accuracy :", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall   :", recall_score(y_true, y_pred))
    print("F1 Score :", f1_score(y_true, y_pred))

# Logistic Regression
model_lr = LogisticRegression()
model_lr.fit(X_train_skb, y_train)
y_pred_lr = model_lr.predict(X_test_skb)
evaluate_model("SelectKBest + Logistic Regression", y_test, y_pred_lr)

# Random Forest
model_rf = RandomForestClassifier(random_state=42)
model_rf.fit(X_train_skb, y_train)
y_pred_rf = model_rf.predict(X_test_skb)
evaluate_model("SelectKBest + Random Forest", y_test, y_pred_rf)

# SVM
model_svm = SVC(kernel="linear", random_state=42)
model_svm.fit(X_train_skb, y_train)
y_pred_svm = model_svm.predict(X_test_skb)
evaluate_model("SelectKBest + SVM", y_test, y_pred_svm)

"""**Insight**
- Melatih model Logistic Regression, Random Forest, dan SVM dengan 10 fitur terpilih dari SelectKBest untuk klasifikasi tumor (malignant/benign).

- Akurasi SVM 0.9737 (F1 Score 0.9630, terbaik), Logistic Regression 0.9561 (F1 Score 0.9383), Random Forest 0.9561 (F1 Score 0.9367).

### RFE
"""

model_rfe_rf = RandomForestClassifier(random_state=42)
model_rfe_rf.fit(X_train_rfe_rf, y_train)
y_pred_rfe_rf = model_rfe_rf.predict(X_test_rfe_rf)

model_rfe_lr = LogisticRegression()
model_rfe_lr.fit(X_train_rfe, y_train)
y_pred_rfe_lr = model_rfe_lr.predict(X_test_rfe)

model_rfe_svm = SVC(kernel="linear", random_state=42)
model_rfe_svm.fit(X_train_rfe_svm, y_train)
y_pred_rfe_svm = model_rfe_svm.predict(X_test_rfe_svm)

"""**Insight:**
Melatih model yang sama dengan 10 fitur terpilih dari RFE (Recursive Feature Elimination) untuk klasifikasi.
"""

def evaluate_model(name, y_true, y_pred):
    print(f"\nModel: {name}")
    print("Accuracy :", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall   :", recall_score(y_true, y_pred))
    print("F1 Score :", f1_score(y_true, y_pred))

# Evaluasi
evaluate_model("RFE + LR", y_test, y_pred_rfe_lr)
evaluate_model("RFE + RF", y_test, y_pred_rfe_rf)
evaluate_model("RFE + SVM", y_test, y_pred_rfe_svm)

"""**Insight:**
- Melihat hasil dari modelling menggunakan fitur RFE

- Logistic Regression 0.9737 (F1 Score 0.9639, sangat baik), Random Forest 0.9737 (F1 Score 0.9630), SVM 0.9474 (F1 Score 0.9250, terendah).

# Evaluasi
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import pandas as pd

# List untuk menyimpan hasil evaluasi
evaluation_results = []

# Fungsi evaluasi (ubah jadi simpan ke list)
def evaluate_model_to_list(name, y_true, y_pred):
    # Menghitung metrik evaluasi
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    # Menghitung confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Menyimpan hasil evaluasi ke list
    evaluation_results.append({
        'Model': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1,
        'Confusion Matrix': cm
    })

# Evaluasi semua model
evaluate_model_to_list("SelectKBest + Logistic Regression", y_test, y_pred_lr)
evaluate_model_to_list("SelectKBest + Random Forest", y_test, y_pred_rf)
evaluate_model_to_list("SelectKBest + SVM", y_test, y_pred_svm)
evaluate_model_to_list("RFE + LR", y_test, y_pred_rfe_lr)
evaluate_model_to_list("RFE + RF", y_test, y_pred_rfe_rf)
evaluate_model_to_list("RFE + SVM", y_test, y_pred_rfe_svm)

# Tampilkan dalam dataframe
results_df = pd.DataFrame(evaluation_results)

# Tampilkan hasil evaluasi dan confusion matrix
print("\nHasil Evaluasi Semua Model:")
display(results_df.sort_values(by='F1 Score', ascending=False))

# Menampilkan confusion matrix untuk setiap model
for result in evaluation_results:
    print(f"\nConfusion Matrix untuk {result['Model']}:")
    print(result['Confusion Matrix'])

"""**Insight:**
- Mengumpulkan metrik (Accuracy, Precision, Recall, F1 Score) semua model, menampilkannya dalam tabel dari yang terbaik

- Tabel menunjukkan RFE + Logistic Regression dan SelectKBest + SVM punya F1 Score tertinggi (~0.963).
"""

# Urutkan berdasarkan F1 Score dan reset index
results_sorted = results_df.sort_values(by='F1 Score', ascending=False).reset_index(drop=True)

# Plot
results_sorted.plot(
    x='Model',
    y=['Accuracy', 'Precision', 'Recall', 'F1 Score'],
    kind='bar',
    figsize=(12, 6),
    colormap='Set2'
)

plt.title('Perbandingan Performa Model')
plt.ylabel('Skor')
plt.xticks(rotation=45, ha='right')
plt.ylim(0.85, 1.01)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""**Insight Evaluasi Model:**

1. Berdasarkan barplot hasil evaluasi enam kombinasi model dan metode seleksi fitur, model RFE + Logistic Regression memberikan performa paling seimbang dengan F1 Score tertinggi (0.9639), diikuti sangat dekat oleh SelectKBest + SVM dan RFE + Random Forest yang juga memiliki akurasi dan precision 100%, namun sedikit lebih rendah di aspek recall.

2. Metode seleksi fitur RFE (Recursive Feature Elimination) terbukti lebih konsisten memberikan performa tinggi dibandingkan SelectKBest. Di sisi lain, algoritma SVM dan Random Forest mampu mencapai precision sempurna, namun trade-off-nya adalah recall sedikit lebih rendah (mungkin cenderung overfitting pada data benign).

3. Secara keseluruhan, model RFE + Logistic Regression dapat direkomendasikan karena memberikan keseimbangan terbaik antara semua metrik evaluasi.

### Metrik evaluasi ROC-AUC dan PR-AUC

**insight:**
- Menghitung ROC-AUC dan PR-AUC untuk mengevaluasi kemampuan model membedakan kelas.
"""

from sklearn.metrics import roc_auc_score, precision_recall_curve, auc

model_list = [
    ("RFE + LR", model_rfe_lr, X_test_rfe),
    ("RFE + RF", model_rfe_rf, X_test_rfe_rf),
    ("RFE + SVM", model_rfe_svm, X_test_rfe_svm),
    ("SelectKBest + Logistic Regression", model_lr, X_test_skb),
    ("SelectKBest + Random Forest", model_rf, X_test_skb),
    ("SelectKBest + SVM", model_svm, X_test_skb)
]

for name, model, X_test in model_list:
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test)[:, 1]
    else:
        # Untuk SVM jika tidak ada predict_proba
        y_prob = model.decision_function(X_test)

    roc_auc = roc_auc_score(y_test, y_prob)
    precision, recall, _ = precision_recall_curve(y_test, y_prob)
    pr_auc = auc(recall, precision)

    print(f"{name}")
    print(f"  ROC-AUC : {roc_auc:.4f}")
    print(f"  PR-AUC  : {pr_auc:.4f}")
    print("-" * 40)

"""**Insight Metrik Evaluasi ROC-AUC dan PR-AUC :**
1. Model terbaik secara ROC-AUC dan PR-AUC adalah SelectKBest + SVM

- ROC-AUC: 0.9987

- PR-AUC : 0.9978
2. Model ini menunjukkan kemampuan terbaik dalam membedakan antara kelas dan tetap sangat baik dalam situasi data tidak seimbang.

3. Model lain yang juga sangat kuat:

- RFE + LR (ROC-AUC: 0.9974, PR-AUC: 0.9957)

- SelectKBest + Logistic Regression (ROC-AUC: 0.9974, PR-AUC: 0.9956)
Kedua model ini sangat kompetitif, hanya sedikit di bawah SVM.

- Model dengan performa paling rendah dalam metrik ini:

- SelectKBest + Random Forest (ROC-AUC: 0.9894, PR-AUC: 0.9848)
Meski tetap tinggi, performanya sedikit di bawah yang lain.
"""